{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9746dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark dê comparação de strings e benchmark de leitura e escrita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46fdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime as dt\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e78116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
    "from Bio import SeqIO, Phylo, AlignIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c18206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analise_fasta import analisar_fasta\n",
    "from system_info import system_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464b233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "from parsl import python_app, ThreadPoolExecutor\n",
    "from concurrent.futures import wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc016e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUCLEOS = int(os.getenv(\"NSLOTS\", \"4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01265cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = Path('../data')\n",
    "INPUT_SEQUENCES = PATH_DATA / 'full_dataset_plasmodium'\n",
    "PATH_OUT = PATH_DATA / f'out_{os.uname().nodename}_{dt.datetime.now().strftime(\"%H%M%S\")}'\n",
    "SEQUENCIAS_ALINHADAS = PATH_OUT / 'tmp'\n",
    "ARVORES_FILOGENETICAS = PATH_OUT / 'Trees'\n",
    "SUBARVORES = PATH_OUT / 'Subtrees'\n",
    "PROVENANCE = PATH_DATA / 'provenance'\n",
    "SIMILARIDADES = PATH_DATA / 'Similaridades'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a72f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretórios de saída, se não existirem\n",
    "os.makedirs(PATH_OUT, exist_ok=True)\n",
    "os.makedirs(SEQUENCIAS_ALINHADAS, exist_ok=True)\n",
    "os.makedirs(ARVORES_FILOGENETICAS, exist_ok=True)\n",
    "os.makedirs(SUBARVORES, exist_ok=True)\n",
    "os.makedirs(SIMILARIDADES, exist_ok=True)\n",
    "os.makedirs(PROVENANCE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198488e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1b3283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x76aba87c7ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Configuração do Parsl ---\n",
    "parsl.load(\n",
    "    parsl.config.Config(\n",
    "        executors=[ThreadPoolExecutor(max_threads=NUCLEOS)],\n",
    "        strategy=None\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b613ddb",
   "metadata": {},
   "source": [
    "### Gera os paramtros de sequencias e entradas aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc99370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gera_json import gera_parametros_aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a174de",
   "metadata": {},
   "source": [
    "### Utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d1ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_lista(lista, n_partes):\n",
    "    k, m = divmod(len(lista), n_partes)\n",
    "    return [lista[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n_partes)]\n",
    "\n",
    "\n",
    "def calcula_numero_comparacoes(m: int, n: int) -> int:\n",
    "    \"\"\"\n",
    "    Calcula f(m, n) = C(m, 2) * n² = (m * (m - 1) // 2) * n ** 2.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    m : int\n",
    "        Inteiro não-negativo (m ≥ 0).\n",
    "    n : int\n",
    "        Inteiro (pode ser zero ou positivo).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    int\n",
    "        Valor de f(m, n).\n",
    "    \"\"\"\n",
    "    return (m * (m - 1) // 2) * n ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074de0de",
   "metadata": {},
   "source": [
    "### Pega os dados das sequencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2abf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensivo em leitura\n",
    "def contar_sequencias(caminho_arquivo: Path) -> int:\n",
    "    \"\"\"\n",
    "    Conta a quantidade de sequências em um arquivo fasta.\n",
    "    A contagem é feita pelo número de linhas de cabeçalho.\n",
    "    \"\"\"\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        conteudo = f.read()\n",
    "\n",
    "    return conteudo.count(\">\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff19fb9",
   "metadata": {},
   "source": [
    "### Funções de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73483466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_Trees():\n",
    "    for name_file_trees in os.listdir(ARVORES_FILOGENETICAS):\n",
    "        if name_file_trees != \"file.gitkeep\":\n",
    "            os.remove(ARVORES_FILOGENETICAS / name_file_trees)\n",
    "\n",
    "def clean_tmp():\n",
    "    for name_file_tmp in os.listdir(SEQUENCIAS_ALINHADAS):\n",
    "        if name_file_tmp != \"file.gitkeep\":\n",
    "            os.remove(SEQUENCIAS_ALINHADAS / name_file_tmp)\n",
    "\n",
    "\n",
    "def clean_NoPipe():\n",
    "    for file_name in os.listdir(INPUT_SEQUENCES):\n",
    "        if 'NoPipe' in file_name or file_name.endswith('.dnd'):\n",
    "            os.remove(INPUT_SEQUENCES / file_name)\n",
    "\n",
    "\n",
    "def clean_subtrees():\n",
    "    for name_file in os.listdir(SUBARVORES):\n",
    "        if name_file != \"file.gitkeep\":\n",
    "            os.remove(SUBARVORES / name_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421ee85",
   "metadata": {},
   "source": [
    "### Funções de validação das sequências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff16bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se todos os caracteres da sequência são válidos\n",
    "def validate_fasta_protein(file_path: Path) -> bool:\n",
    "    valid_chars = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "    if not file_path.exists():\n",
    "        logging.error(f\"Arquivo não encontrado: {file_path}\")\n",
    "        return False\n",
    "    for line in file_path.read_text().splitlines():\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        if not set(line.strip()).issubset(valid_chars):\n",
    "            logging.warning(f\"Sequência inválida em: {file_path}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Verifica se existe algum id duplicado na sequencia\n",
    "def has_duplicate_ids(file_path: Path) -> bool:\n",
    "    if not file_path.exists():\n",
    "        logging.error(f\"Arquivo não encontrado: {file_path}\")\n",
    "        return False\n",
    "    seen = set()\n",
    "    for record in SeqIO.parse(file_path, 'fasta'):\n",
    "        if record.id in seen:\n",
    "            logging.warning(f\"ID duplicado encontrado: {record.id}\")\n",
    "            return True\n",
    "        seen.add(record.id)\n",
    "    return False\n",
    "\n",
    "# Remove sequencias duplicadas\n",
    "def remove_pipe(name: str, path_in_fasta: Path) -> Path:\n",
    "    sequences = list(SeqIO.parse(path_in_fasta, \"fasta\"))\n",
    "    unique_sequences = {str(seq.seq): seq for seq in sequences}\n",
    "    output_file_tmp = path_in_fasta / f\"{name}_NoPipe\"\n",
    "    SeqIO.write(unique_sequences.values(), output_file_tmp, \"fasta\")\n",
    "    logging.info(f\"Arquivo sem duplicatas salvo em: {output_file_tmp}\")\n",
    "    return output_file_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcdaf0",
   "metadata": {},
   "source": [
    "### Analisa as sequencias para posterior inserção em modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_sequencias_fasta(config_file: Path) -> list:\n",
    "\n",
    "    with open(config_file, \"r\", encoding=\"utf-8\") as arquivo:\n",
    "        par = json.load(arquivo)\n",
    "\n",
    "    entradas_original = par['entradas']\n",
    "\n",
    "    resultado = []\n",
    "\n",
    "    for file in par['entradas']:\n",
    "        sequencia_fasta = INPUT_SEQUENCES / file\n",
    "        resultado.append(analisar_fasta(sequencia_fasta))\n",
    "\n",
    "    par['entradas'] = resultado\n",
    "\n",
    "    with open(PATH_OUT / \"temp.json\", \"w\", encoding=\"utf-8\") as arquivo:\n",
    "        json.dump(par, arquivo, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return entradas_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a825c0b",
   "metadata": {},
   "source": [
    "### Função de alinhamento sequências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37b9b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def alinhar_sequencias(parametros: dict, files: list[Path]) -> None:\n",
    "    match parametros['algoritmo']:\n",
    "        case \"clustalw\":\n",
    "            command_parameters = []\n",
    "\n",
    "            for key, value in parametros['parametros'].items():\n",
    "                if isinstance(value, bool) and value:\n",
    "                    command_parameters.append(key)\n",
    "                else:\n",
    "                    command_parameters.append(f\"{key}={value}\")\n",
    "\n",
    "            for infile in files:\n",
    "                command_files = [f\"-INFILE={infile}\"]\n",
    "                command_files.append(f\"-OUTFILE={SEQUENCIAS_ALINHADAS / infile.with_suffix('.aln').name}\")\n",
    "\n",
    "                command = [\"clustalw\"] + command_parameters + command_files\n",
    "                result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "                if result.stderr and result.stderr.strip():\n",
    "                    print(\"Erro durante execução:\", result.stderr.strip(), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30e4b5",
   "metadata": {},
   "source": [
    "### Construção de árvores filogenéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9517a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def constructor_tree(arquivos_alinhamento: list[Path], output_format):\n",
    "    for arquivo_alinhamentos in arquivos_alinhamento:\n",
    "        with arquivo_alinhamentos.open(\"r\") as handle:\n",
    "            alignment = AlignIO.read(handle, \"clustal\")\n",
    "            \n",
    "        calculator = DistanceCalculator('identity')\n",
    "        distance_matrix = calculator.get_distance(alignment)\n",
    "\n",
    "        # Escolha do modelo evolutivo nj ou upgma\n",
    "        tree = DistanceTreeConstructor().nj(distance_matrix)\n",
    "\n",
    "        # Escreve o arquivo de saida\n",
    "        path_out_tree = ARVORES_FILOGENETICAS / arquivo_alinhamentos.with_suffix(\".\" + output_format).name\n",
    "        Phylo.write(tree, path_out_tree, output_format) # Escreve em arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed527cff",
   "metadata": {},
   "source": [
    "### Construção das subárvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c5805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @python_app\n",
    "def sub_tree(path, name_subtree, data_format: str, data_output_path: Path, extension_format: str):\n",
    "    # Salva a árvore\n",
    "    tree = Phylo.read(path, data_format) # Lê de arquivo\n",
    "    name_subtree = name_subtree.rsplit(\".\", 1)[0]\n",
    "\n",
    "    # Lista caminhos das subárvores (que posteriormente serão utilizadas para compor a matriz de subárvores)\n",
    "    row_subtree = []\n",
    "\n",
    "    for clade in tree.find_clades(terminal=False):\n",
    "        subtree = Phylo.BaseTree.Tree(clade)\n",
    "        filepath_out = os.path.join(data_output_path,f'{name_subtree}_{clade.name}.{extension_format}')\n",
    "        Phylo.write(subtree, filepath_out, data_format) # Escreve em arquivo        \n",
    "        row_subtree.append(filepath_out)\n",
    "            \n",
    "    return row_subtree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d6aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher_matriz(matriz, valor_preenchimento, max_columns: int):\n",
    "    # Preencher as células vazias com o valor de preenchimento\n",
    "\n",
    "    for row in matriz:\n",
    "        while len(row) < max_columns:\n",
    "            row.append(valor_preenchimento)\n",
    "\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a45bfc",
   "metadata": {},
   "source": [
    "### Comparação entre subárvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7931bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subarvores_possiveis(dir: Path, tree_format: str) -> list[str]:\n",
    "    # matriz com todas as subárvores\n",
    "    matriz_subtree = []\n",
    "\n",
    "    for file in ARVORES_FILOGENETICAS.iterdir():\n",
    "        matriz_subtree.append(\n",
    "            sub_tree(\n",
    "                file,\n",
    "                file.name,\n",
    "                tree_format,\n",
    "                SUBARVORES,\n",
    "                tree_format\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return matriz_subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89caae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_maf(path_1: str, path_2: str, tree_format: str) -> float:\n",
    "    # Verifica se os caminhos das subárvores existe\n",
    "    if path_1 is None or path_2 is None:\n",
    "        return None\n",
    "    \n",
    "    subtree_1 = Phylo.read(path_1, tree_format)\n",
    "    subtree_2 = Phylo.read(path_2, tree_format)\n",
    "\n",
    "    list_1 = {i.name for i in subtree_1.get_terminals()}\n",
    "    list_2 = {i.name for i in subtree_2.get_terminals()}\n",
    "\n",
    "    size_list_1 = len(list_1)\n",
    "    size_list_2 = len(list_2)\n",
    "\n",
    "    intersection = list_1.intersection(list_2)\n",
    "\n",
    "    return len(intersection) / max(size_list_1, size_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a419e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def calcula_similaridade(max_rows: int, max_columns: int, matriz_subtree: list[list[Path]], tree_format: str) -> dict:\n",
    "    dict_maf_database = {}\n",
    "\n",
    "    for i in range(max_rows):\n",
    "        for j in range(max_columns):\n",
    "            for k in range(i + 1, max_rows):\n",
    "                for l in range(max_columns):\n",
    "                    g_maf = grade_maf(matriz_subtree[i][j], matriz_subtree[k][l], tree_format)\n",
    "\n",
    "                    if g_maf is not None and g_maf >= 0:\n",
    "                        if g_maf not in dict_maf_database:\n",
    "                            dict_maf_database[g_maf] = {}\n",
    "\n",
    "                    if os.path.split(matriz_subtree[i][j])[1] not in dict_maf_database[g_maf]:\n",
    "                        dict_maf_database[g_maf][os.path.split(matriz_subtree[i][j])[1]] = []\n",
    "\n",
    "                    dict_maf_database[g_maf][os.path.split(matriz_subtree[i][j])[1]].append(os.path.split(matriz_subtree[k][l])[1])\n",
    "    \n",
    "    return dict_maf_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b1228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a179212b",
   "metadata": {},
   "source": [
    "### Faz a busca das subárvores filogenéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_NoPipe()\n",
    "clean_tmp()\n",
    "clean_Trees()\n",
    "clean_subtrees()\n",
    "\n",
    "gera_parametros_aleatorios()\n",
    "\n",
    "lista_saida = []\n",
    "if __name__ == '__main__':\n",
    "    inicio = time.perf_counter()\n",
    "\n",
    "    # Falta validar as serquências\n",
    "    analisar_sequencias_fasta(\"config.json\")\n",
    "    \n",
    "    with open(\"config.json\", \"r\", encoding=\"utf-8\") as arquivo:\n",
    "        parametros = json.load(arquivo)\n",
    "\n",
    "    files = [INPUT_SEQUENCES / nome for nome in parametros['entradas']]\n",
    "    listas = dividir_lista(files, NUCLEOS)    # Divide a lista em várias de acordo com o número de núcloes usados\n",
    "    futuros = [alinhar_sequencias(parametros, lista) for lista in listas]   # Submete as tarefas ao Parsl\n",
    "    wait(futuros)   # Espera todas terminarem\n",
    "\n",
    "    listas = dividir_lista(list(SEQUENCIAS_ALINHADAS.iterdir()), NUCLEOS)    # Divide a lista em várias de acordo com o número de núcloes usados\n",
    "    futuros = [constructor_tree(lista, parametros['tree_format']) for lista in listas]   # Submete as tarefas ao Parsl\n",
    "    wait(futuros)   # Espera todas terminarem\n",
    "\n",
    "    matriz_subtree = subarvores_possiveis(ARVORES_FILOGENETICAS, parametros['tree_format'])\n",
    "\n",
    "    max_columns = max(len(row) for row in matriz_subtree)\n",
    "    max_rows = len(matriz_subtree)\n",
    "\n",
    "    matriz_subtree = preencher_matriz(matriz_subtree, None, max_columns)\n",
    "\n",
    "    futures = calcula_similaridade(max_rows, max_columns, matriz_subtree, parametros['tree_format'])\n",
    "    dict_maf_database = futures.result()\n",
    "\n",
    "    # Salva o dicionário de similaridades\n",
    "    with open(SIMILARIDADES / f\"similaridades_{dt.datetime.now().strftime('%Y%m%d%H%M%S')}.json\", \"w\", encoding=\"utf-8\") as arquivo:\n",
    "        json.dump(dict_maf_database, arquivo, ensure_ascii=False, indent=4)\n",
    "\n",
    "    with open(PATH_OUT / \"temp.json\", \"r\", encoding=\"utf-8\") as arquivo:\n",
    "        par = json.load(arquivo)\n",
    "\n",
    "    par['resultado'] = {\"Inicio\": inicio,\n",
    "                        \"Fim\": time.perf_counter(),\n",
    "                        \"num_procs\": NUCLEOS}\n",
    "        \n",
    "    par['host'] = system_summary()\n",
    "        \n",
    "    with open(PROVENANCE / f\"dados_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\", \"w\", encoding=\"utf-8\") as arquivo:\n",
    "        json.dump(par, arquivo, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    os.remove(PATH_OUT / \"temp.json\")\n",
    "\n",
    "shutil.rmtree(PATH_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
